{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "53ede503",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, json\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "sys.path.append(os.path.abspath(\"../src\"))\n",
    "\n",
    "from feature_selection import vote_feature_selection\n",
    "from models import (\n",
    "    train_knn, train_decision_tree, train_svm,\n",
    "    train_gradient_boosting, train_adaboost, train_xgboost,\n",
    "    evaluate_model, evaluate_thresholds\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b629e11",
   "metadata": {},
   "source": [
    "<h3>Load Data</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7beae273",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (1025, 14)\n",
      "Target distribution:\n",
      " target\n",
      "1    0.513171\n",
      "0    0.486829\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"../data/processed/heart.csv\")\n",
    "\n",
    "target = \"target\"\n",
    "X = df.drop(columns=[target])\n",
    "y = df[target]\n",
    "\n",
    "print(\"Dataset shape:\", df.shape)\n",
    "print(\"Target distribution:\\n\", y.value_counts(normalize=True))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55097e6c",
   "metadata": {},
   "source": [
    "<h3>Train/Test Split</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "31435b9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (820, 13)\n",
      "Test shape: (205, 13)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y,\n",
    "    test_size=0.20,\n",
    "    stratify=y,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "print(\"Train shape:\", X_train.shape)\n",
    "print(\"Test shape:\", X_test.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d9a1161",
   "metadata": {},
   "source": [
    "<h3>Feature Selection</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4fba89b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shawa\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\feature_selection\\_rfe.py:300: UserWarning: Found n_features_to_select=18 > n_features=13. There will be no feature selection and all features will be kept.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Selected Features: ['exang', 'cp', 'ca', 'oldpeak', 'sex', 'slope', 'thalach', 'thal', 'age', 'restecg', 'fbs', 'trestbps', 'chol']\n",
      "\n",
      "Votes:\n",
      " exang       5\n",
      "cp          5\n",
      "ca          5\n",
      "oldpeak     5\n",
      "sex         5\n",
      "slope       5\n",
      "thalach     5\n",
      "thal        5\n",
      "age         5\n",
      "restecg     5\n",
      "fbs         5\n",
      "trestbps    5\n",
      "chol        5\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "selected_features, votes = vote_feature_selection(X_train, y_train, top_n=18)\n",
    "\n",
    "print(\"\\nSelected Features:\", selected_features)\n",
    "print(\"\\nVotes:\\n\", votes)\n",
    "\n",
    "with open(\"../data/processed/selected_features.json\", \"w\") as f:\n",
    "    json.dump(selected_features, f)\n",
    "\n",
    "X_train_sel = X_train[selected_features]\n",
    "X_test_sel = X_test[selected_features]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5c3fd4c",
   "metadata": {},
   "source": [
    "<h3>Models</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "99ac052a",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_model = train_knn(X_train_sel, y_train)\n",
    "svm_model = train_svm(X_train_sel, y_train)\n",
    "tree_model = train_decision_tree(X_train_sel, y_train)\n",
    "gb_model = train_gradient_boosting(X_train_sel, y_train)\n",
    "ada_model = train_adaboost(X_train_sel, y_train)\n",
    "xgb_model = train_xgboost(X_train_sel, y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b6ba3fc",
   "metadata": {},
   "source": [
    "<h3>Evaluation</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3a96b152",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== KNN =====\n",
      "Accuracy: 0.6926829268292682\n",
      "Precision: 0.6944444444444444\n",
      "Recall: 0.7142857142857143\n",
      "F1 Score: 0.704225352112676\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.67      0.68       100\n",
      "           1       0.69      0.71      0.70       105\n",
      "\n",
      "    accuracy                           0.69       205\n",
      "   macro avg       0.69      0.69      0.69       205\n",
      "weighted avg       0.69      0.69      0.69       205\n",
      "\n",
      "Confusion Matrix:\n",
      " [[67 33]\n",
      " [30 75]]\n",
      "========================\n",
      "\n",
      "\n",
      "===== SVM =====\n",
      "Accuracy: 0.7170731707317073\n",
      "Precision: 0.7079646017699115\n",
      "Recall: 0.7619047619047619\n",
      "F1 Score: 0.7339449541284404\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.67      0.70       100\n",
      "           1       0.71      0.76      0.73       105\n",
      "\n",
      "    accuracy                           0.72       205\n",
      "   macro avg       0.72      0.72      0.72       205\n",
      "weighted avg       0.72      0.72      0.72       205\n",
      "\n",
      "Confusion Matrix:\n",
      " [[67 33]\n",
      " [25 80]]\n",
      "========================\n",
      "\n",
      "\n",
      "===== Decision Tree =====\n",
      "Accuracy: 0.8341463414634146\n",
      "Precision: 0.8446601941747572\n",
      "Recall: 0.8285714285714286\n",
      "F1 Score: 0.8365384615384616\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.84      0.83       100\n",
      "           1       0.84      0.83      0.84       105\n",
      "\n",
      "    accuracy                           0.83       205\n",
      "   macro avg       0.83      0.83      0.83       205\n",
      "weighted avg       0.83      0.83      0.83       205\n",
      "\n",
      "Confusion Matrix:\n",
      " [[84 16]\n",
      " [18 87]]\n",
      "========================\n",
      "\n",
      "\n",
      "===== Gradient Boosting =====\n",
      "Accuracy: 0.9707317073170731\n",
      "Precision: 0.9714285714285714\n",
      "Recall: 0.9714285714285714\n",
      "F1 Score: 0.9714285714285714\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.97      0.97       100\n",
      "           1       0.97      0.97      0.97       105\n",
      "\n",
      "    accuracy                           0.97       205\n",
      "   macro avg       0.97      0.97      0.97       205\n",
      "weighted avg       0.97      0.97      0.97       205\n",
      "\n",
      "Confusion Matrix:\n",
      " [[ 97   3]\n",
      " [  3 102]]\n",
      "========================\n",
      "\n",
      "\n",
      "===== AdaBoost =====\n",
      "Accuracy: 0.9707317073170731\n",
      "Precision: 0.9626168224299065\n",
      "Recall: 0.9809523809523809\n",
      "F1 Score: 0.9716981132075472\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.96      0.97       100\n",
      "           1       0.96      0.98      0.97       105\n",
      "\n",
      "    accuracy                           0.97       205\n",
      "   macro avg       0.97      0.97      0.97       205\n",
      "weighted avg       0.97      0.97      0.97       205\n",
      "\n",
      "Confusion Matrix:\n",
      " [[ 96   4]\n",
      " [  2 103]]\n",
      "========================\n",
      "\n",
      "\n",
      "===== XGBoost =====\n",
      "Accuracy: 0.9560975609756097\n",
      "Precision: 0.9705882352941176\n",
      "Recall: 0.9428571428571428\n",
      "F1 Score: 0.9565217391304348\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.97      0.96       100\n",
      "           1       0.97      0.94      0.96       105\n",
      "\n",
      "    accuracy                           0.96       205\n",
      "   macro avg       0.96      0.96      0.96       205\n",
      "weighted avg       0.96      0.96      0.96       205\n",
      "\n",
      "Confusion Matrix:\n",
      " [[97  3]\n",
      " [ 6 99]]\n",
      "========================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "\n",
    "results.append(evaluate_model(knn_model, X_test_sel, y_test, \"KNN\"))\n",
    "results.append(evaluate_model(svm_model, X_test_sel, y_test, \"SVM\"))\n",
    "results.append(evaluate_model(tree_model, X_test_sel, y_test, \"Decision Tree\"))\n",
    "results.append(evaluate_model(gb_model, X_test_sel, y_test, \"Gradient Boosting\"))\n",
    "results.append(evaluate_model(ada_model, X_test_sel, y_test, \"AdaBoost\"))\n",
    "results.append(evaluate_model(xgb_model, X_test_sel, y_test, \"XGBoost\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "798ee371",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>KNN</td>\n",
       "      <td>0.692683</td>\n",
       "      <td>0.694444</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.704225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SVM</td>\n",
       "      <td>0.717073</td>\n",
       "      <td>0.707965</td>\n",
       "      <td>0.761905</td>\n",
       "      <td>0.733945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.834146</td>\n",
       "      <td>0.844660</td>\n",
       "      <td>0.828571</td>\n",
       "      <td>0.836538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Gradient Boosting</td>\n",
       "      <td>0.970732</td>\n",
       "      <td>0.971429</td>\n",
       "      <td>0.971429</td>\n",
       "      <td>0.971429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AdaBoost</td>\n",
       "      <td>0.970732</td>\n",
       "      <td>0.962617</td>\n",
       "      <td>0.980952</td>\n",
       "      <td>0.971698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.956098</td>\n",
       "      <td>0.970588</td>\n",
       "      <td>0.942857</td>\n",
       "      <td>0.956522</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               model  accuracy  precision    recall        f1\n",
       "0                KNN  0.692683   0.694444  0.714286  0.704225\n",
       "1                SVM  0.717073   0.707965  0.761905  0.733945\n",
       "2      Decision Tree  0.834146   0.844660  0.828571  0.836538\n",
       "3  Gradient Boosting  0.970732   0.971429  0.971429  0.971429\n",
       "4           AdaBoost  0.970732   0.962617  0.980952  0.971698\n",
       "5            XGBoost  0.956098   0.970588  0.942857  0.956522"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e59d3c75",
   "metadata": {},
   "source": [
    "<h3>Threshold Optimization</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "357a22a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'KNN':     threshold  precision    recall        f1\n",
       " 0        0.05   0.603550  0.971429  0.744526\n",
       " 1        0.10   0.603550  0.971429  0.744526\n",
       " 2        0.15   0.615385  0.914286  0.735632\n",
       " 3        0.20   0.615385  0.914286  0.735632\n",
       " 4        0.25   0.615385  0.914286  0.735632\n",
       " 5        0.30   0.645669  0.780952  0.706897\n",
       " 6        0.35   0.645669  0.780952  0.706897\n",
       " 7        0.40   0.645669  0.780952  0.706897\n",
       " 8        0.45   0.694444  0.714286  0.704225\n",
       " 9        0.50   0.694444  0.714286  0.704225\n",
       " 10       0.55   0.694444  0.714286  0.704225\n",
       " 11       0.60   0.759494  0.571429  0.652174\n",
       " 12       0.65   0.759494  0.571429  0.652174\n",
       " 13       0.70   0.759494  0.571429  0.652174\n",
       " 14       0.75   0.852459  0.495238  0.626506\n",
       " 15       0.80   0.852459  0.495238  0.626506\n",
       " 16       0.85   0.852459  0.495238  0.626506\n",
       " 17       0.90   1.000000  0.380952  0.551724\n",
       " 18       0.95   1.000000  0.380952  0.551724,\n",
       " 'SVM':     threshold  precision    recall        f1\n",
       " 0        0.05   0.514706  1.000000  0.679612\n",
       " 1        0.10   0.527638  1.000000  0.690789\n",
       " 2        0.15   0.551913  0.961905  0.701389\n",
       " 3        0.20   0.565714  0.942857  0.707143\n",
       " 4        0.25   0.566265  0.895238  0.693727\n",
       " 5        0.30   0.581250  0.885714  0.701887\n",
       " 6        0.35   0.590909  0.866667  0.702703\n",
       " 7        0.40   0.609929  0.819048  0.699187\n",
       " 8        0.45   0.669291  0.809524  0.732759\n",
       " 9        0.50   0.694915  0.780952  0.735426\n",
       " 10       0.55   0.712963  0.733333  0.723005\n",
       " 11       0.60   0.718750  0.657143  0.686567\n",
       " 12       0.65   0.695122  0.542857  0.609626\n",
       " 13       0.70   0.741935  0.438095  0.550898\n",
       " 14       0.75   0.795918  0.371429  0.506494\n",
       " 15       0.80   0.870968  0.257143  0.397059\n",
       " 16       0.85   0.785714  0.104762  0.184874\n",
       " 17       0.90   1.000000  0.019048  0.037383\n",
       " 18       0.95   0.000000  0.000000  0.000000,\n",
       " 'Decision Tree':     threshold  precision    recall        f1\n",
       " 0        0.05   0.662420  0.990476  0.793893\n",
       " 1        0.10   0.662420  0.990476  0.793893\n",
       " 2        0.15   0.751825  0.980952  0.851240\n",
       " 3        0.20   0.751825  0.980952  0.851240\n",
       " 4        0.25   0.751825  0.980952  0.851240\n",
       " 5        0.30   0.751825  0.980952  0.851240\n",
       " 6        0.35   0.751825  0.980952  0.851240\n",
       " 7        0.40   0.793103  0.876190  0.832579\n",
       " 8        0.45   0.819820  0.866667  0.842593\n",
       " 9        0.50   0.844660  0.828571  0.836538\n",
       " 10       0.55   0.844660  0.828571  0.836538\n",
       " 11       0.60   0.917647  0.742857  0.821053\n",
       " 12       0.65   0.917647  0.742857  0.821053\n",
       " 13       0.70   0.917647  0.742857  0.821053\n",
       " 14       0.75   0.960526  0.695238  0.806630\n",
       " 15       0.80   0.960526  0.695238  0.806630\n",
       " 16       0.85   0.960526  0.695238  0.806630\n",
       " 17       0.90   0.964912  0.523810  0.679012\n",
       " 18       0.95   0.964912  0.523810  0.679012,\n",
       " 'Gradient Boosting':     threshold  precision    recall        f1\n",
       " 0        0.05   0.681818  1.000000  0.810811\n",
       " 1        0.10   0.704698  1.000000  0.826772\n",
       " 2        0.15   0.750000  1.000000  0.857143\n",
       " 3        0.20   0.789474  1.000000  0.882353\n",
       " 4        0.25   0.846774  1.000000  0.917031\n",
       " 5        0.30   0.867769  1.000000  0.929204\n",
       " 6        0.35   0.895652  0.980952  0.936364\n",
       " 7        0.40   0.962617  0.980952  0.971698\n",
       " 8        0.45   0.971698  0.980952  0.976303\n",
       " 9        0.50   0.971429  0.971429  0.971429\n",
       " 10       0.55   0.971429  0.971429  0.971429\n",
       " 11       0.60   0.980198  0.942857  0.961165\n",
       " 12       0.65   0.980000  0.933333  0.956098\n",
       " 13       0.70   0.979798  0.923810  0.950980\n",
       " 14       0.75   0.979167  0.895238  0.935323\n",
       " 15       0.80   0.978261  0.857143  0.913706\n",
       " 16       0.85   0.975309  0.752381  0.849462\n",
       " 17       0.90   0.972222  0.666667  0.790960\n",
       " 18       0.95   1.000000  0.485714  0.653846,\n",
       " 'AdaBoost':     threshold  precision    recall        f1\n",
       " 0        0.05   0.512195  1.000000  0.677419\n",
       " 1        0.10   0.512195  1.000000  0.677419\n",
       " 2        0.15   0.546875  1.000000  0.707071\n",
       " 3        0.20   0.600000  1.000000  0.750000\n",
       " 4        0.25   0.664557  1.000000  0.798479\n",
       " 5        0.30   0.729167  1.000000  0.843373\n",
       " 6        0.35   0.777778  1.000000  0.875000\n",
       " 7        0.40   0.860656  1.000000  0.925110\n",
       " 8        0.45   0.953704  0.980952  0.967136\n",
       " 9        0.50   0.962617  0.980952  0.971698\n",
       " 10       0.55   1.000000  0.971429  0.985507\n",
       " 11       0.60   1.000000  0.904762  0.950000\n",
       " 12       0.65   1.000000  0.819048  0.900524\n",
       " 13       0.70   1.000000  0.619048  0.764706\n",
       " 14       0.75   1.000000  0.438095  0.609272\n",
       " 15       0.80   1.000000  0.314286  0.478261\n",
       " 16       0.85   1.000000  0.057143  0.108108\n",
       " 17       0.90   0.000000  0.000000  0.000000\n",
       " 18       0.95   0.000000  0.000000  0.000000,\n",
       " 'XGBoost':     threshold  precision    recall        f1\n",
       " 0        0.05   0.673077  1.000000  0.804598\n",
       " 1        0.10   0.690789  1.000000  0.817121\n",
       " 2        0.15   0.734266  1.000000  0.846774\n",
       " 3        0.20   0.755396  1.000000  0.860656\n",
       " 4        0.25   0.783582  1.000000  0.878661\n",
       " 5        0.30   0.818898  0.990476  0.896552\n",
       " 6        0.35   0.858333  0.980952  0.915556\n",
       " 7        0.40   0.901786  0.961905  0.930876\n",
       " 8        0.45   0.925926  0.952381  0.938967\n",
       " 9        0.50   0.970588  0.942857  0.956522\n",
       " 10       0.55   0.979798  0.923810  0.950980\n",
       " 11       0.60   0.979798  0.923810  0.950980\n",
       " 12       0.65   0.979381  0.904762  0.940594\n",
       " 13       0.70   0.978495  0.866667  0.919192\n",
       " 14       0.75   0.978261  0.857143  0.913706\n",
       " 15       0.80   0.978022  0.847619  0.908163\n",
       " 16       0.85   0.975000  0.742857  0.843243\n",
       " 17       0.90   0.967742  0.571429  0.718563\n",
       " 18       0.95   0.958333  0.438095  0.601307}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "threshold_tables = {\n",
    "    \"KNN\": evaluate_thresholds(knn_model, X_test_sel, y_test),\n",
    "    \"SVM\": evaluate_thresholds(svm_model, X_test_sel, y_test),\n",
    "    \"Decision Tree\": evaluate_thresholds(tree_model, X_test_sel, y_test),\n",
    "    \"Gradient Boosting\": evaluate_thresholds(gb_model, X_test_sel, y_test),\n",
    "    \"AdaBoost\": evaluate_thresholds(ada_model, X_test_sel, y_test),\n",
    "    \"XGBoost\": evaluate_thresholds(xgb_model, X_test_sel, y_test),\n",
    "}\n",
    "\n",
    "threshold_tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "be618f7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model results to: ../data/processed/model_results.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>KNN</td>\n",
       "      <td>0.692683</td>\n",
       "      <td>0.694444</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.704225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SVM</td>\n",
       "      <td>0.717073</td>\n",
       "      <td>0.707965</td>\n",
       "      <td>0.761905</td>\n",
       "      <td>0.733945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.834146</td>\n",
       "      <td>0.844660</td>\n",
       "      <td>0.828571</td>\n",
       "      <td>0.836538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Gradient Boosting</td>\n",
       "      <td>0.970732</td>\n",
       "      <td>0.971429</td>\n",
       "      <td>0.971429</td>\n",
       "      <td>0.971429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AdaBoost</td>\n",
       "      <td>0.970732</td>\n",
       "      <td>0.962617</td>\n",
       "      <td>0.980952</td>\n",
       "      <td>0.971698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.956098</td>\n",
       "      <td>0.970588</td>\n",
       "      <td>0.942857</td>\n",
       "      <td>0.956522</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               model  accuracy  precision    recall        f1\n",
       "0                KNN  0.692683   0.694444  0.714286  0.704225\n",
       "1                SVM  0.717073   0.707965  0.761905  0.733945\n",
       "2      Decision Tree  0.834146   0.844660  0.828571  0.836538\n",
       "3  Gradient Boosting  0.970732   0.971429  0.971429  0.971429\n",
       "4           AdaBoost  0.970732   0.962617  0.980952  0.971698\n",
       "5            XGBoost  0.956098   0.970588  0.942857  0.956522"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df = pd.DataFrame(results)\n",
    "results_path = \"../data/processed/model_results.csv\"\n",
    "\n",
    "results_df.to_csv(results_path, index=False)\n",
    "\n",
    "print(\"Saved model results to:\", results_path)\n",
    "results_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "70559191",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models saved successfully!\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "os.makedirs(\"../data/models\", exist_ok=True)\n",
    "\n",
    "joblib.dump(knn_model, \"../data/models/knn_model.pkl\")\n",
    "joblib.dump(svm_model, \"../data/models/svm_model.pkl\")\n",
    "joblib.dump(tree_model, \"../data/models/decision_tree.pkl\")\n",
    "joblib.dump(gb_model, \"../data/models/gradient_boosting.pkl\")\n",
    "joblib.dump(ada_model, \"../data/models/adaboost.pkl\")\n",
    "joblib.dump(xgb_model, \"../data/models/xgboost.pkl\")\n",
    "\n",
    "print(\"Models saved successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8b0b6ca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_sel.to_csv(\"../data/processed/X_test_selected.csv\", index=False)\n",
    "y_test.to_csv(\"../data/processed/y_test.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11d9347d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
